{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import boston_housing\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Boston housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.count_nonzero(train_data[42]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.0830e-02, 0.0000e+00, 5.1900e+00, 0.0000e+00, 5.1500e-01,\n",
       "       6.3160e+00, 3.8100e+01, 6.4584e+00, 5.0000e+00, 2.2400e+02,\n",
       "       2.0200e+01, 3.8971e+02, 5.6800e+00])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[42] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu',\n",
    "    input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating your approach using K-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "k = 4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 10\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "processing fold # 1\n",
      "processing fold # 2\n",
      "processing fold # 3\n"
     ]
    }
   ],
   "source": [
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "        train_data[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "         [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "         axis=0)\n",
    "    model = build_model()\n",
    "    model.fit(partial_train_data, partial_train_targets,\n",
    "              epochs=num_epochs, batch_size=1, verbose=0)\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.629143476486206, 2.713118553161621, 2.5826797485351562, 2.7579989433288574]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.67073518037796"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Epoch 1/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 228.9825 - mae: 11.4985 - val_loss: 39.2727 - val_mae: 3.9706\n",
      "Epoch 2/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 30.4596 - mae: 3.8174 - val_loss: 28.1104 - val_mae: 3.2708\n",
      "Epoch 3/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 22.0167 - mae: 3.2280 - val_loss: 20.1091 - val_mae: 2.7947\n",
      "Epoch 4/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 18.6269 - mae: 2.9006 - val_loss: 18.1482 - val_mae: 2.8426\n",
      "Epoch 5/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 16.5625 - mae: 2.7997 - val_loss: 16.1675 - val_mae: 2.5389\n",
      "Epoch 6/50\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 15.6731 - mae: 2.6432 - val_loss: 14.3951 - val_mae: 2.4744\n",
      "Epoch 7/50\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 14.1350 - mae: 2.5124 - val_loss: 12.9821 - val_mae: 2.5523\n",
      "Epoch 8/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 13.7096 - mae: 2.4542 - val_loss: 12.9583 - val_mae: 2.3368\n",
      "Epoch 9/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 12.9877 - mae: 2.3613 - val_loss: 12.6504 - val_mae: 2.3874\n",
      "Epoch 10/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.8598 - mae: 2.3936 - val_loss: 11.4799 - val_mae: 2.1498\n",
      "Epoch 11/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 12.3204 - mae: 2.3074 - val_loss: 13.8333 - val_mae: 2.6380\n",
      "Epoch 12/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.8656 - mae: 2.2156 - val_loss: 10.8676 - val_mae: 2.3805\n",
      "Epoch 13/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 10.8602 - mae: 2.2308 - val_loss: 11.1573 - val_mae: 2.0555\n",
      "Epoch 14/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 10.8112 - mae: 2.2061 - val_loss: 9.9404 - val_mae: 2.2797\n",
      "Epoch 15/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 10.7166 - mae: 2.2003 - val_loss: 9.7824 - val_mae: 2.2357\n",
      "Epoch 16/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 10.4662 - mae: 2.0941 - val_loss: 9.0300 - val_mae: 2.1855\n",
      "Epoch 17/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.7849 - mae: 2.0950 - val_loss: 9.2157 - val_mae: 1.9371\n",
      "Epoch 18/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.6149 - mae: 2.0928 - val_loss: 9.9601 - val_mae: 1.9940\n",
      "Epoch 19/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.0899 - mae: 2.0506 - val_loss: 8.9717 - val_mae: 1.9047\n",
      "Epoch 20/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.2812 - mae: 2.0252 - val_loss: 9.0533 - val_mae: 2.0549\n",
      "Epoch 21/50\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 9.0612 - mae: 2.0035 - val_loss: 8.8325 - val_mae: 2.1389\n",
      "Epoch 22/50\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 9.0294 - mae: 2.0330 - val_loss: 8.2701 - val_mae: 2.0278\n",
      "Epoch 23/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.5097 - mae: 1.9812 - val_loss: 10.0682 - val_mae: 2.2734\n",
      "Epoch 24/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.5247 - mae: 1.9678 - val_loss: 8.4732 - val_mae: 2.0493\n",
      "Epoch 25/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.4974 - mae: 1.9081 - val_loss: 8.1529 - val_mae: 2.0071\n",
      "Epoch 26/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.5541 - mae: 1.9243 - val_loss: 7.8790 - val_mae: 2.0138\n",
      "Epoch 27/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.1655 - mae: 1.9214 - val_loss: 10.4933 - val_mae: 2.4207\n",
      "Epoch 28/50\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 8.3682 - mae: 1.8729 - val_loss: 8.6522 - val_mae: 2.0161\n",
      "Epoch 29/50\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 8.1100 - mae: 1.8885 - val_loss: 8.2849 - val_mae: 2.1599\n",
      "Epoch 30/50\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 8.2432 - mae: 1.8519 - val_loss: 9.1626 - val_mae: 2.0555\n",
      "Epoch 31/50\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 7.8128 - mae: 1.8171 - val_loss: 9.2359 - val_mae: 2.2330\n",
      "Epoch 32/50\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 7.4743 - mae: 1.8127 - val_loss: 7.9436 - val_mae: 2.1334\n",
      "Epoch 33/50\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 7.6169 - mae: 1.7995 - val_loss: 7.8422 - val_mae: 2.1379\n",
      "Epoch 34/50\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 7.4221 - mae: 1.7735 - val_loss: 8.9370 - val_mae: 1.9756\n",
      "Epoch 35/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.4565 - mae: 1.7235 - val_loss: 7.8070 - val_mae: 1.9663\n",
      "Epoch 36/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.4893 - mae: 1.8033 - val_loss: 7.5181 - val_mae: 1.9758\n",
      "Epoch 37/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.1693 - mae: 1.8369 - val_loss: 9.0609 - val_mae: 2.2806\n",
      "Epoch 38/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.3615 - mae: 1.8002 - val_loss: 8.2938 - val_mae: 2.2395\n",
      "Epoch 39/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.0284 - mae: 1.7620 - val_loss: 7.4257 - val_mae: 2.0231\n",
      "Epoch 40/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.7512 - mae: 1.7595 - val_loss: 8.3380 - val_mae: 2.0822\n",
      "Epoch 41/50\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 6.5794 - mae: 1.7208 - val_loss: 8.0736 - val_mae: 2.1908\n",
      "Epoch 42/50\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 7.0006 - mae: 1.7668 - val_loss: 7.9668 - val_mae: 2.1157\n",
      "Epoch 43/50\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 7.0285 - mae: 1.7513 - val_loss: 8.3203 - val_mae: 2.0095\n",
      "Epoch 44/50\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 6.2227 - mae: 1.7039 - val_loss: 7.6183 - val_mae: 1.9811\n",
      "Epoch 45/50\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 6.9778 - mae: 1.7172 - val_loss: 8.3085 - val_mae: 2.1496\n",
      "Epoch 46/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.6124 - mae: 1.6946 - val_loss: 8.1556 - val_mae: 1.9738\n",
      "Epoch 47/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.1767 - mae: 1.7247 - val_loss: 7.3698 - val_mae: 1.9222\n",
      "Epoch 48/50\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 6.4323 - mae: 1.7171 - val_loss: 9.6308 - val_mae: 2.2795\n",
      "Epoch 49/50\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 6.3229 - mae: 1.6845 - val_loss: 8.4742 - val_mae: 2.2724\n",
      "Epoch 50/50\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 6.1039 - mae: 1.6917 - val_loss: 8.0252 - val_mae: 2.0751\n",
      "processing fold # 1\n",
      "Epoch 1/50\n",
      "303/303 [==============================] - 1s 3ms/step - loss: 216.1040 - mae: 11.2863 - val_loss: 41.0475 - val_mae: 4.4598\n",
      "Epoch 2/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 33.6532 - mae: 3.8864 - val_loss: 19.2686 - val_mae: 3.3610\n",
      "Epoch 3/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 21.8623 - mae: 3.1660 - val_loss: 17.3481 - val_mae: 3.1424\n",
      "Epoch 4/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 17.6004 - mae: 2.8828 - val_loss: 16.3353 - val_mae: 3.1287\n",
      "Epoch 5/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 14.9314 - mae: 2.6499 - val_loss: 13.9170 - val_mae: 2.7940\n",
      "Epoch 6/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 14.2286 - mae: 2.5186 - val_loss: 12.1651 - val_mae: 2.7166\n",
      "Epoch 7/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 12.3422 - mae: 2.3666 - val_loss: 12.7521 - val_mae: 2.8211\n",
      "Epoch 8/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.4487 - mae: 2.3194 - val_loss: 15.9340 - val_mae: 3.1069\n",
      "Epoch 9/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.1618 - mae: 2.2857 - val_loss: 11.7164 - val_mae: 2.6700\n",
      "Epoch 10/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.1347 - mae: 2.2432 - val_loss: 10.3461 - val_mae: 2.5036\n",
      "Epoch 11/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 10.3189 - mae: 2.2135 - val_loss: 11.9242 - val_mae: 2.5744\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 1ms/step - loss: 10.3713 - mae: 2.1575 - val_loss: 10.3740 - val_mae: 2.4815\n",
      "Epoch 13/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 10.1612 - mae: 2.1678 - val_loss: 11.9770 - val_mae: 2.7356\n",
      "Epoch 14/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.7718 - mae: 2.1278 - val_loss: 12.0803 - val_mae: 2.7771\n",
      "Epoch 15/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.7268 - mae: 2.1361 - val_loss: 10.1522 - val_mae: 2.5057\n",
      "Epoch 16/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.0641 - mae: 2.0221 - val_loss: 9.2526 - val_mae: 2.4309\n",
      "Epoch 17/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.4508 - mae: 2.0631 - val_loss: 9.8755 - val_mae: 2.4708\n",
      "Epoch 18/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.9922 - mae: 2.0360 - val_loss: 9.7694 - val_mae: 2.4276\n",
      "Epoch 19/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.9442 - mae: 2.0024 - val_loss: 10.4406 - val_mae: 2.5709\n",
      "Epoch 20/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.8894 - mae: 2.0423 - val_loss: 9.6552 - val_mae: 2.4126\n",
      "Epoch 21/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.5938 - mae: 1.9357 - val_loss: 10.7919 - val_mae: 2.5798\n",
      "Epoch 22/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.9533 - mae: 1.9365 - val_loss: 10.9505 - val_mae: 2.6403\n",
      "Epoch 23/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.1241 - mae: 1.9361 - val_loss: 9.8695 - val_mae: 2.4684\n",
      "Epoch 24/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.3308 - mae: 1.9766 - val_loss: 9.6550 - val_mae: 2.4245\n",
      "Epoch 25/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.3186 - mae: 1.9291 - val_loss: 9.4461 - val_mae: 2.3782\n",
      "Epoch 26/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.3004 - mae: 1.9260 - val_loss: 9.8056 - val_mae: 2.4746\n",
      "Epoch 27/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.6792 - mae: 1.8828 - val_loss: 8.3900 - val_mae: 2.2569\n",
      "Epoch 28/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.8343 - mae: 1.8251 - val_loss: 8.9617 - val_mae: 2.3627\n",
      "Epoch 29/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.6320 - mae: 1.8877 - val_loss: 10.1804 - val_mae: 2.4961\n",
      "Epoch 30/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.6421 - mae: 1.7934 - val_loss: 9.7292 - val_mae: 2.4259\n",
      "Epoch 31/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.5774 - mae: 1.8259 - val_loss: 10.0584 - val_mae: 2.4428\n",
      "Epoch 32/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.3675 - mae: 1.7636 - val_loss: 9.5611 - val_mae: 2.3894\n",
      "Epoch 33/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.3045 - mae: 1.7321 - val_loss: 10.7469 - val_mae: 2.5583\n",
      "Epoch 34/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.7659 - mae: 1.7556 - val_loss: 9.0167 - val_mae: 2.3247\n",
      "Epoch 35/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.1659 - mae: 1.7806 - val_loss: 8.6294 - val_mae: 2.3003\n",
      "Epoch 36/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.0537 - mae: 1.7850 - val_loss: 9.5966 - val_mae: 2.4802\n",
      "Epoch 37/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.8905 - mae: 1.7369 - val_loss: 11.7548 - val_mae: 2.7760\n",
      "Epoch 38/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.8564 - mae: 1.7512 - val_loss: 11.9661 - val_mae: 2.7944\n",
      "Epoch 39/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.6307 - mae: 1.7296 - val_loss: 8.2893 - val_mae: 2.2262\n",
      "Epoch 40/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.0118 - mae: 1.7220 - val_loss: 7.7914 - val_mae: 2.1993\n",
      "Epoch 41/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.5670 - mae: 1.7167 - val_loss: 7.8031 - val_mae: 2.1708\n",
      "Epoch 42/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.7007 - mae: 1.6648 - val_loss: 8.5389 - val_mae: 2.2610\n",
      "Epoch 43/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.4037 - mae: 1.6579 - val_loss: 9.5157 - val_mae: 2.4093\n",
      "Epoch 44/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.5140 - mae: 1.7889 - val_loss: 7.9244 - val_mae: 2.1288\n",
      "Epoch 45/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 5.9906 - mae: 1.6441 - val_loss: 9.5775 - val_mae: 2.4678\n",
      "Epoch 46/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.0519 - mae: 1.6746 - val_loss: 9.5325 - val_mae: 2.4339\n",
      "Epoch 47/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 5.9464 - mae: 1.6734 - val_loss: 9.7975 - val_mae: 2.3753\n",
      "Epoch 48/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.0186 - mae: 1.6123 - val_loss: 8.3056 - val_mae: 2.1697\n",
      "Epoch 49/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.4564 - mae: 1.6166 - val_loss: 10.2003 - val_mae: 2.5315\n",
      "Epoch 50/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 5.9320 - mae: 1.6785 - val_loss: 8.9674 - val_mae: 2.3631\n",
      "processing fold # 2\n",
      "Epoch 1/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 191.8977 - mae: 10.3070 - val_loss: 31.5813 - val_mae: 4.0335\n",
      "Epoch 2/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 22.6989 - mae: 3.1996 - val_loss: 22.1533 - val_mae: 3.0797\n",
      "Epoch 3/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 17.2382 - mae: 2.8381 - val_loss: 20.4175 - val_mae: 3.0840\n",
      "Epoch 4/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 14.7280 - mae: 2.6734 - val_loss: 18.2416 - val_mae: 2.7455\n",
      "Epoch 5/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 12.8164 - mae: 2.5092 - val_loss: 16.7643 - val_mae: 2.6682\n",
      "Epoch 6/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.8380 - mae: 2.4967 - val_loss: 16.2915 - val_mae: 2.7889\n",
      "Epoch 7/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.2702 - mae: 2.3955 - val_loss: 16.0232 - val_mae: 2.5477\n",
      "Epoch 8/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 10.9340 - mae: 2.3296 - val_loss: 18.9980 - val_mae: 2.9395\n",
      "Epoch 9/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 10.7237 - mae: 2.2777 - val_loss: 16.4681 - val_mae: 2.5420\n",
      "Epoch 10/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 10.0003 - mae: 2.1943 - val_loss: 16.3794 - val_mae: 2.6209\n",
      "Epoch 11/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.1679 - mae: 2.1308 - val_loss: 15.7008 - val_mae: 2.5265\n",
      "Epoch 12/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.2083 - mae: 2.1031 - val_loss: 15.5288 - val_mae: 2.5112\n",
      "Epoch 13/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.6528 - mae: 2.0606 - val_loss: 17.1679 - val_mae: 2.6051\n",
      "Epoch 14/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.7394 - mae: 2.0355 - val_loss: 15.0899 - val_mae: 2.4910\n",
      "Epoch 15/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.5038 - mae: 1.9934 - val_loss: 14.6801 - val_mae: 2.5778\n",
      "Epoch 16/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.9700 - mae: 1.9659 - val_loss: 13.6839 - val_mae: 2.4644\n",
      "Epoch 17/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.6496 - mae: 1.8635 - val_loss: 16.4400 - val_mae: 2.9817\n",
      "Epoch 18/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.7588 - mae: 1.9596 - val_loss: 14.0698 - val_mae: 2.3964\n",
      "Epoch 19/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.0875 - mae: 1.9834 - val_loss: 14.1065 - val_mae: 2.4808\n",
      "Epoch 20/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.6235 - mae: 1.9606 - val_loss: 13.8271 - val_mae: 2.5653\n",
      "Epoch 21/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.1041 - mae: 1.8565 - val_loss: 14.7637 - val_mae: 2.5229\n",
      "Epoch 22/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.2037 - mae: 1.8752 - val_loss: 13.7767 - val_mae: 2.3228\n",
      "Epoch 23/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.2373 - mae: 1.8883 - val_loss: 14.4467 - val_mae: 2.6376\n",
      "Epoch 24/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.3255 - mae: 1.8799 - val_loss: 13.6087 - val_mae: 2.4462\n",
      "Epoch 25/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.8734 - mae: 1.8318 - val_loss: 15.9005 - val_mae: 2.6089\n",
      "Epoch 26/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.5766 - mae: 1.7812 - val_loss: 15.2796 - val_mae: 2.7189\n",
      "Epoch 27/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.9430 - mae: 1.8534 - val_loss: 14.5003 - val_mae: 2.4652\n",
      "Epoch 28/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.9383 - mae: 1.8123 - val_loss: 14.6723 - val_mae: 2.4932\n",
      "Epoch 29/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.7850 - mae: 1.7591 - val_loss: 13.7908 - val_mae: 2.4194\n",
      "Epoch 30/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.3493 - mae: 1.7355 - val_loss: 15.5968 - val_mae: 2.5661\n",
      "Epoch 31/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.7048 - mae: 1.7709 - val_loss: 14.5573 - val_mae: 2.5893\n",
      "Epoch 32/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.4601 - mae: 1.7407 - val_loss: 13.5194 - val_mae: 2.3985\n",
      "Epoch 33/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.1790 - mae: 1.6989 - val_loss: 13.3080 - val_mae: 2.4696\n",
      "Epoch 34/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 5.9598 - mae: 1.7144 - val_loss: 14.5189 - val_mae: 2.5339\n",
      "Epoch 35/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 5.7127 - mae: 1.6686 - val_loss: 16.5019 - val_mae: 2.8565\n",
      "Epoch 36/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.0773 - mae: 1.7369 - val_loss: 13.9003 - val_mae: 2.5765\n",
      "Epoch 37/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 5.9499 - mae: 1.6892 - val_loss: 12.8196 - val_mae: 2.3365\n",
      "Epoch 38/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 5.8249 - mae: 1.6662 - val_loss: 14.1034 - val_mae: 2.4810\n",
      "Epoch 39/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 5.9475 - mae: 1.6689 - val_loss: 14.8818 - val_mae: 2.7051\n",
      "Epoch 40/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 5.4637 - mae: 1.6124 - val_loss: 13.8519 - val_mae: 2.4716\n",
      "Epoch 41/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 5.8198 - mae: 1.6554 - val_loss: 13.6175 - val_mae: 2.4022\n",
      "Epoch 42/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 5.7748 - mae: 1.6192 - val_loss: 15.6088 - val_mae: 2.7166\n",
      "Epoch 43/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 5.4283 - mae: 1.6339 - val_loss: 13.7384 - val_mae: 2.4962\n",
      "Epoch 44/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 5.4399 - mae: 1.6412 - val_loss: 14.1488 - val_mae: 2.4511\n",
      "Epoch 45/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 5.5064 - mae: 1.5873 - val_loss: 14.8926 - val_mae: 2.6467\n",
      "Epoch 46/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 5.4483 - mae: 1.5944 - val_loss: 13.8450 - val_mae: 2.5078\n",
      "Epoch 47/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 5.1570 - mae: 1.5773 - val_loss: 15.0054 - val_mae: 2.5273\n",
      "Epoch 48/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 5.3821 - mae: 1.6002 - val_loss: 14.4490 - val_mae: 2.5306\n",
      "Epoch 49/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 5.3185 - mae: 1.5762 - val_loss: 15.8200 - val_mae: 2.8580\n",
      "Epoch 50/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 5.0130 - mae: 1.5474 - val_loss: 13.2362 - val_mae: 2.4081\n",
      "processing fold # 3\n",
      "Epoch 1/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 176.4035 - mae: 10.0309 - val_loss: 77.8761 - val_mae: 6.0948\n",
      "Epoch 2/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 31.1989 - mae: 3.7400 - val_loss: 42.5976 - val_mae: 4.3530\n",
      "Epoch 3/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 22.5404 - mae: 3.2192 - val_loss: 34.9694 - val_mae: 3.9554\n",
      "Epoch 4/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 18.9247 - mae: 2.9005 - val_loss: 32.7692 - val_mae: 3.7234\n",
      "Epoch 5/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 16.2462 - mae: 2.6515 - val_loss: 27.0923 - val_mae: 3.3402\n",
      "Epoch 6/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 14.6814 - mae: 2.4890 - val_loss: 22.4912 - val_mae: 2.8828\n",
      "Epoch 7/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 13.3902 - mae: 2.4324 - val_loss: 20.1881 - val_mae: 2.8610\n",
      "Epoch 8/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.7269 - mae: 2.3216 - val_loss: 20.4569 - val_mae: 2.8353\n",
      "Epoch 9/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.8435 - mae: 2.2507 - val_loss: 19.6323 - val_mae: 2.8971\n",
      "Epoch 10/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 11.4719 - mae: 2.2015 - val_loss: 17.3317 - val_mae: 2.6899\n",
      "Epoch 11/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 10.1341 - mae: 2.1564 - val_loss: 16.6539 - val_mae: 2.5334\n",
      "Epoch 12/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 10.4967 - mae: 2.0998 - val_loss: 16.3911 - val_mae: 2.7907\n",
      "Epoch 13/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 10.1390 - mae: 2.1201 - val_loss: 17.0920 - val_mae: 2.6850\n",
      "Epoch 14/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.6417 - mae: 2.0875 - val_loss: 17.5452 - val_mae: 2.7192\n",
      "Epoch 15/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.7433 - mae: 2.0850 - val_loss: 16.6419 - val_mae: 2.6624\n",
      "Epoch 16/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.4828 - mae: 2.0344 - val_loss: 19.0238 - val_mae: 2.7871\n",
      "Epoch 17/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.5775 - mae: 2.0692 - val_loss: 17.1506 - val_mae: 2.8384\n",
      "Epoch 18/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.4428 - mae: 2.0345 - val_loss: 15.0102 - val_mae: 2.5397\n",
      "Epoch 19/50\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 9.1512 - mae: 2.0070 - val_loss: 13.7307 - val_mae: 2.4396\n",
      "Epoch 20/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 9.0496 - mae: 1.9678 - val_loss: 13.3795 - val_mae: 2.4308\n",
      "Epoch 21/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.5943 - mae: 1.8762 - val_loss: 12.9126 - val_mae: 2.4296\n",
      "Epoch 22/50\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 8.2678 - mae: 1.9641 - val_loss: 14.7450 - val_mae: 2.7153\n",
      "Epoch 23/50\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 8.6610 - mae: 1.9267 - val_loss: 12.5669 - val_mae: 2.3925\n",
      "Epoch 24/50\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 8.5189 - mae: 1.9094 - val_loss: 13.0741 - val_mae: 2.4402\n",
      "Epoch 25/50\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 7.9782 - mae: 1.8518 - val_loss: 13.7838 - val_mae: 2.5294\n",
      "Epoch 26/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 8.0211 - mae: 1.9051 - val_loss: 12.6160 - val_mae: 2.4699\n",
      "Epoch 27/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.6876 - mae: 1.8754 - val_loss: 17.3464 - val_mae: 3.1472\n",
      "Epoch 28/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.6647 - mae: 1.8726 - val_loss: 13.6818 - val_mae: 2.5186\n",
      "Epoch 29/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.6627 - mae: 1.8466 - val_loss: 14.4100 - val_mae: 2.8746\n",
      "Epoch 30/50\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 7.7389 - mae: 1.8434 - val_loss: 16.3852 - val_mae: 2.8907\n",
      "Epoch 31/50\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 7.5176 - mae: 1.7954 - val_loss: 15.1648 - val_mae: 2.9839\n",
      "Epoch 32/50\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 7.5041 - mae: 1.7757 - val_loss: 12.1155 - val_mae: 2.4422\n",
      "Epoch 33/50\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 7.3280 - mae: 1.7747 - val_loss: 14.4350 - val_mae: 2.6878\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 2ms/step - loss: 7.4806 - mae: 1.7329 - val_loss: 11.7608 - val_mae: 2.3604\n",
      "Epoch 35/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.5050 - mae: 1.8026 - val_loss: 13.6442 - val_mae: 2.6115\n",
      "Epoch 36/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.1076 - mae: 1.8018 - val_loss: 13.1354 - val_mae: 2.5205\n",
      "Epoch 37/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.0036 - mae: 1.7108 - val_loss: 12.8661 - val_mae: 2.5158\n",
      "Epoch 38/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.9748 - mae: 1.7587 - val_loss: 12.4157 - val_mae: 2.4667\n",
      "Epoch 39/50\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 7.2859 - mae: 1.7808 - val_loss: 13.4054 - val_mae: 2.6337\n",
      "Epoch 40/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.9030 - mae: 1.7187 - val_loss: 13.6700 - val_mae: 2.7063\n",
      "Epoch 41/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 7.1444 - mae: 1.7639 - val_loss: 11.9962 - val_mae: 2.4511\n",
      "Epoch 42/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.5792 - mae: 1.6899 - val_loss: 12.4248 - val_mae: 2.4950\n",
      "Epoch 43/50\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 6.5761 - mae: 1.7009 - val_loss: 11.3924 - val_mae: 2.4045\n",
      "Epoch 44/50\n",
      "303/303 [==============================] - 0s 2ms/step - loss: 6.8743 - mae: 1.6898 - val_loss: 12.0324 - val_mae: 2.4949\n",
      "Epoch 45/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.2307 - mae: 1.6512 - val_loss: 15.6101 - val_mae: 2.8832\n",
      "Epoch 46/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.2746 - mae: 1.6638 - val_loss: 13.7033 - val_mae: 2.7494\n",
      "Epoch 47/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.5965 - mae: 1.6893 - val_loss: 12.5329 - val_mae: 2.5120\n",
      "Epoch 48/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.1940 - mae: 1.6603 - val_loss: 11.2040 - val_mae: 2.3497\n",
      "Epoch 49/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.4324 - mae: 1.6773 - val_loss: 11.6451 - val_mae: 2.4541\n",
      "Epoch 50/50\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 6.3566 - mae: 1.6202 - val_loss: 12.3533 - val_mae: 2.6509\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "all_mae_histories = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    \n",
    "    partial_train_data = np.concatenate(        \n",
    "        [train_data[:i * num_val_samples],\n",
    "        train_data[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "        train_targets[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    model = build_model()\n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=1, verbose=1)\n",
    "    mae_history = history.history['val_mae']\n",
    "    all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_mae_history = [\n",
    "np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 17.2463 - mae: 2.6610\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.fit(train_data, train_targets,\n",
    "          epochs=80, batch_size=16, verbose=0)\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6609795093536377"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mae_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 13)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.random.normal(0,1,13)\n",
    "pred=np.expand_dims(pred, axis=0)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[36.372295]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(pred)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('boston_house.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= models.load_model('boston_house.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.372295"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value= np.float32([1,1,1,1,1,1,1,1,1,1,1])\n",
    "value=np.expand_dims(value, axis=0)\n",
    "prediction[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 13)\n"
     ]
    }
   ],
   "source": [
    "value= np.float32([1,2])\n",
    "value = np.append(value, 3)\n",
    "mean = value.mean()\n",
    "value -= mean\n",
    "std = value.std()\n",
    "value /= std\n",
    "value= np.float32([1,1,1,1,1,1,1,1,1,1,1])\n",
    "value = np.append(value, )\n",
    "value=np.expand_dims(value, axis=0)\n",
    "print(value,mean, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
